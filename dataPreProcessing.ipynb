{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PGN to extended LAN (xLAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNumber of writen games: 397\r"
     ]
    }
   ],
   "source": [
    "def pgn_to_xlan():\n",
    "    from src.data_preprocessing.pgn_to_xlan import pgn_to_xlan\n",
    "\n",
    "    # TODO change to valid paths\n",
    "    pgn_path = \"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/data/pgn/Carlsen.pgn\"\n",
    "    lan_path = \"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/data/xlan/carlsen.xlanplus\"\n",
    "\n",
    "    min_number_of_moves_per_game = 0\n",
    "    number_of_games_to_write = -1  # -1 for all games\n",
    "\n",
    "    pgn_to_lan = pgn_to_xlan(\n",
    "        pgn_path,\n",
    "        lan_path,\n",
    "        min_number_of_moves_per_game=min_number_of_moves_per_game,\n",
    "        number_of_games_to_write=number_of_games_to_write,\n",
    "        generate_all_moves=False,\n",
    "        log=False,\n",
    "        xLanPlus=True,\n",
    "    )\n",
    "\n",
    "    pgn_to_lan.convert_pgn_parallel()\n",
    "\n",
    "pgn_to_xlan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Common and Duplicate Lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use check_duplicates_and_common_lines to check if there are duplicates or common lines in two files.\n",
    "\"\"\"\n",
    "\n",
    "def check_duplicates():\n",
    "    from src.data_preprocessing.check_duplicates_and_common_lines import (\n",
    "        check_duplicates_and_common_lines,\n",
    "    )   \n",
    "    \n",
    "    # TODO what is the validation file?\n",
    "    training_file = \"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/data/xlan/carlsen.xlanplus\"\n",
    "    validation_file = (\n",
    "        \"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/data/xlan/carlsen.xlanplus\"\n",
    "    )\n",
    "\n",
    "    check_duplicates_and_common_lines(training_file, validation_file, delete_common=False, delete_duplicates_from_file_1=True, delete_duplicates_from_file_2=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data():\n",
    "    from src.tokenizer.tokenizer import tokenize_file\n",
    "    \n",
    "    xLAN_path = \"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/data/xlan/carlsen.xlanplus\" # Inout Path \n",
    "    token_path = \"./src/tokenizer/xlanplus_tokens.json\" # keep this, correct like this\n",
    "    tokenized_path = \"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/data/tokens/carlsen.tok\" # Output path\n",
    "\n",
    "    tokenize_file(token_path, xLAN_path, tokenized_path, batch_size=20000) # eventually smaller batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove lines with more than x tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lines_with_too_many_tokens(input_file_path, output_file_path, token_limit=768):\n",
    "    with open(input_file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    print(f\"Number of lines in {input_file_path}: {len(lines)}\")\n",
    "    lines_to_keep = []\n",
    "    removed_count = 0\n",
    "\n",
    "    for line in lines:\n",
    "        if len(line.split()) <= token_limit:\n",
    "            lines_to_keep.append(line)\n",
    "        else:\n",
    "            removed_count += 1\n",
    "\n",
    "    print(f\"Number of lines in {output_file_path}: {len(lines_to_keep)}\")\n",
    "    with open(output_file_path, \"w\") as file:\n",
    "        file.writelines(lines_to_keep)\n",
    "\n",
    "    return removed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(): \n",
    "    input_file_path = \"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/data/tokens/carlsen.tok\"\n",
    "    output_file_path = \"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/data/tokens/carlsen_max_768.tok\"\n",
    "    removed_lines = remove_lines_with_too_many_tokens(input_file_path, output_file_path)\n",
    "    print(f\"Number of removed lines: {removed_lines}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
