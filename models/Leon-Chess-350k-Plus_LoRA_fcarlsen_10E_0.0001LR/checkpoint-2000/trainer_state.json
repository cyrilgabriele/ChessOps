{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.714285714285714,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 0.3465864956378937,
      "learning_rate": 9.857142857142858e-05,
      "loss": 3.1389,
      "step": 50
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.1589714139699936,
      "learning_rate": 9.714285714285715e-05,
      "loss": 2.0241,
      "step": 100
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 0.1754605919122696,
      "learning_rate": 9.571428571428573e-05,
      "loss": 1.799,
      "step": 150
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.2697646915912628,
      "learning_rate": 9.428571428571429e-05,
      "loss": 1.6411,
      "step": 200
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.24851331114768982,
      "learning_rate": 9.285714285714286e-05,
      "loss": 1.4711,
      "step": 250
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.3169618546962738,
      "learning_rate": 9.142857142857143e-05,
      "loss": 1.2046,
      "step": 300
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2956179082393646,
      "learning_rate": 9e-05,
      "loss": 1.1171,
      "step": 350
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.3269919753074646,
      "learning_rate": 8.857142857142857e-05,
      "loss": 1.0578,
      "step": 400
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 0.3428509533405304,
      "learning_rate": 8.714285714285715e-05,
      "loss": 1.0225,
      "step": 450
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.29180771112442017,
      "learning_rate": 8.571428571428571e-05,
      "loss": 0.9786,
      "step": 500
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.27144402265548706,
      "learning_rate": 8.428571428571429e-05,
      "loss": 0.9576,
      "step": 550
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.3581955134868622,
      "learning_rate": 8.285714285714287e-05,
      "loss": 0.9099,
      "step": 600
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 0.4146336019039154,
      "learning_rate": 8.142857142857143e-05,
      "loss": 0.8705,
      "step": 650
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.38880646228790283,
      "learning_rate": 8e-05,
      "loss": 0.8218,
      "step": 700
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.4426712691783905,
      "learning_rate": 7.857142857142858e-05,
      "loss": 0.7926,
      "step": 750
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.39550191164016724,
      "learning_rate": 7.714285714285715e-05,
      "loss": 0.7699,
      "step": 800
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 0.40289780497550964,
      "learning_rate": 7.571428571428571e-05,
      "loss": 0.7589,
      "step": 850
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.3370875418186188,
      "learning_rate": 7.428571428571429e-05,
      "loss": 0.7475,
      "step": 900
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 0.392191082239151,
      "learning_rate": 7.285714285714286e-05,
      "loss": 0.7412,
      "step": 950
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.3176032602787018,
      "learning_rate": 7.142857142857143e-05,
      "loss": 0.7317,
      "step": 1000
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.4204550087451935,
      "learning_rate": 7e-05,
      "loss": 0.7235,
      "step": 1050
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 0.28957435488700867,
      "learning_rate": 6.857142857142858e-05,
      "loss": 0.7203,
      "step": 1100
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 0.3723706305027008,
      "learning_rate": 6.714285714285714e-05,
      "loss": 0.7128,
      "step": 1150
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.4042946994304657,
      "learning_rate": 6.571428571428571e-05,
      "loss": 0.7087,
      "step": 1200
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.4568556845188141,
      "learning_rate": 6.428571428571429e-05,
      "loss": 0.7041,
      "step": 1250
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 0.3170071542263031,
      "learning_rate": 6.285714285714286e-05,
      "loss": 0.7012,
      "step": 1300
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 0.5373228192329407,
      "learning_rate": 6.142857142857143e-05,
      "loss": 0.6959,
      "step": 1350
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3560371398925781,
      "learning_rate": 6e-05,
      "loss": 0.6934,
      "step": 1400
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 0.4659982919692993,
      "learning_rate": 5.8571428571428575e-05,
      "loss": 0.6876,
      "step": 1450
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.44103267788887024,
      "learning_rate": 5.714285714285714e-05,
      "loss": 0.6923,
      "step": 1500
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 0.45148342847824097,
      "learning_rate": 5.571428571428572e-05,
      "loss": 0.6868,
      "step": 1550
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.665203869342804,
      "learning_rate": 5.428571428571428e-05,
      "loss": 0.6839,
      "step": 1600
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 0.4077892005443573,
      "learning_rate": 5.285714285714286e-05,
      "loss": 0.6839,
      "step": 1650
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 0.31230810284614563,
      "learning_rate": 5.142857142857143e-05,
      "loss": 0.6719,
      "step": 1700
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.32083660364151,
      "learning_rate": 5e-05,
      "loss": 0.6736,
      "step": 1750
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.2893981635570526,
      "learning_rate": 4.8571428571428576e-05,
      "loss": 0.6682,
      "step": 1800
    },
    {
      "epoch": 5.285714285714286,
      "grad_norm": 0.27988100051879883,
      "learning_rate": 4.714285714285714e-05,
      "loss": 0.6724,
      "step": 1850
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 0.2858056426048279,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 0.6685,
      "step": 1900
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 0.4756219983100891,
      "learning_rate": 4.428571428571428e-05,
      "loss": 0.6632,
      "step": 1950
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.3249981999397278,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 0.6603,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2000,
  "total_flos": 1.321436837620224e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
