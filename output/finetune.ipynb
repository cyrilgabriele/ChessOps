{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575ccaf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:41.239934Z",
     "iopub.status.busy": "2024-05-08T11:57:41.239704Z",
     "iopub.status.idle": "2024-05-08T11:57:41.245008Z",
     "shell.execute_reply": "2024-05-08T11:57:41.244640Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.009629,
     "end_time": "2024-05-08T11:57:41.246211",
     "exception": false,
     "start_time": "2024-05-08T11:57:41.236582",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# declare a list tasks whose products you want to use as inputs\n",
    "upstream = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bf5881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:41.250033Z",
     "iopub.status.busy": "2024-05-08T11:57:41.249884Z",
     "iopub.status.idle": "2024-05-08T11:57:41.252228Z",
     "shell.execute_reply": "2024-05-08T11:57:41.251865Z"
    },
    "papermill": {
     "duration": 0.005707,
     "end_time": "2024-05-08T11:57:41.253630",
     "exception": false,
     "start_time": "2024-05-08T11:57:41.247923",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "chess_player = \"f'carlsen'\"\n",
    "product = {\"nb\": \"/Users/larscarlschmid/Documents/_repos/ChessOps/output/finetune.ipynb\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513f4130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:41.257315Z",
     "iopub.status.busy": "2024-05-08T11:57:41.257159Z",
     "iopub.status.idle": "2024-05-08T11:57:42.747701Z",
     "shell.execute_reply": "2024-05-08T11:57:42.747359Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 1.493717,
     "end_time": "2024-05-08T11:57:42.748913",
     "exception": false,
     "start_time": "2024-05-08T11:57:41.255196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from src.train import ChessTrainer\n",
    "from peft import LoraConfig, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d50c66e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:42.752056Z",
     "iopub.status.busy": "2024-05-08T11:57:42.751842Z",
     "iopub.status.idle": "2024-05-08T11:57:42.754058Z",
     "shell.execute_reply": "2024-05-08T11:57:42.753810Z"
    },
    "papermill": {
     "duration": 0.004607,
     "end_time": "2024-05-08T11:57:42.754891",
     "exception": false,
     "start_time": "2024-05-08T11:57:42.750284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## HYPERPARAMETERS\n",
    "BATCH_SIZE = 16  # use the largest batch size that fits on your GPU\n",
    "SAVE_STEPS = 2000  # how often to save a checkpoint\n",
    "LOGGING_STEPS = 50  # how often to validate model and publish it to Weights & Biases\n",
    "EPOCHS = 1  # how many epochs to train for - how many times to go through the dataset\n",
    "LEARNING_RATE = 0.0001  # learning rate - how fast the model should learn\n",
    "SKIP_VALIDATION = True  # skip validation and only save model checkpoints\n",
    "WEIGHTS_AND_BIASES_ENABLED = False  # enable logging to Weights & Biases\n",
    "USE_FP16 = True  # enable mixed precision training (GPU only)\n",
    "XLANPLUS_ENABLED = True  # use xLanPlus tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b9dc5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:42.757401Z",
     "iopub.status.busy": "2024-05-08T11:57:42.757273Z",
     "iopub.status.idle": "2024-05-08T11:57:42.759079Z",
     "shell.execute_reply": "2024-05-08T11:57:42.758772Z"
    },
    "papermill": {
     "duration": 0.004036,
     "end_time": "2024-05-08T11:57:42.759977",
     "exception": false,
     "start_time": "2024-05-08T11:57:42.755941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MODEL\n",
    "PEFT_BASE_MODEL = \"Leon-LLM/Leon-Chess-350k-BOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17469474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:42.762770Z",
     "iopub.status.busy": "2024-05-08T11:57:42.762650Z",
     "iopub.status.idle": "2024-05-08T11:57:42.764532Z",
     "shell.execute_reply": "2024-05-08T11:57:42.764289Z"
    },
    "papermill": {
     "duration": 0.004213,
     "end_time": "2024-05-08T11:57:42.765364",
     "exception": false,
     "start_time": "2024-05-08T11:57:42.761151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CONFIG FOR FINE-TUNING\n",
    "R = 128  # lower means faster training, but might underfit because of less complexity (experiments don't show that training time increases, which is rather weird)\n",
    "LORA_ALPHA = 32  # scaling factor that adjusts the magnitude of the combined result (balances the pretrained modelâ€™s knowledge and the new task-specific adaptation)\n",
    "LORA_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b73c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:42.767972Z",
     "iopub.status.busy": "2024-05-08T11:57:42.767856Z",
     "iopub.status.idle": "2024-05-08T11:57:42.769598Z",
     "shell.execute_reply": "2024-05-08T11:57:42.769348Z"
    },
    "papermill": {
     "duration": 0.003953,
     "end_time": "2024-05-08T11:57:42.770392",
     "exception": false,
     "start_time": "2024-05-08T11:57:42.766439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PATHS\n",
    "# dataset = \"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/data/tokens/carlsen_max_768.tok\"\n",
    "dataset = \"./data/tokens/carlsen_max_768.tok\"\n",
    "# output_dir = f\"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/models/\"\n",
    "output_dir = f\"models/\"\n",
    "model_name = f\"{PEFT_BASE_MODEL.split('/')[1]}_LoRA_{chess_player}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e9fd22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:42.772713Z",
     "iopub.status.busy": "2024-05-08T11:57:42.772609Z",
     "iopub.status.idle": "2024-05-08T11:57:42.774528Z",
     "shell.execute_reply": "2024-05-08T11:57:42.774291Z"
    },
    "papermill": {
     "duration": 0.003941,
     "end_time": "2024-05-08T11:57:42.775284",
     "exception": false,
     "start_time": "2024-05-08T11:57:42.771343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    peft_config = LoraConfig(  # https://huggingface.co/docs/peft/v0.10.0/en/package_reference/lora#peft.LoraConfig\n",
    "        task_type=\"CAUSAL_LM\",  # This does not need to be changed for our use case\n",
    "        inference_mode=False,  # don't change this for training, only later for inference\n",
    "        r=R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "    )\n",
    "\n",
    "    peft_model = get_peft_model(\n",
    "        AutoModelForCausalLM.from_pretrained(PEFT_BASE_MODEL), peft_config\n",
    "    )\n",
    "\n",
    "    return peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e907a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:42.777653Z",
     "iopub.status.busy": "2024-05-08T11:57:42.777542Z",
     "iopub.status.idle": "2024-05-08T11:57:42.779793Z",
     "shell.execute_reply": "2024-05-08T11:57:42.779586Z"
    },
    "papermill": {
     "duration": 0.004316,
     "end_time": "2024-05-08T11:57:42.780564",
     "exception": false,
     "start_time": "2024-05-08T11:57:42.776248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataset, output_dir, debug=True):\n",
    "    if debug:\n",
    "        print(f\"model: {model}\")\n",
    "        print(f\"dataset: {dataset}\")\n",
    "        print(f\"output_dir: {output_dir}\")\n",
    "\n",
    "    trainer = ChessTrainer(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        epochs=EPOCHS,\n",
    "        input_file=dataset,\n",
    "        output_dir=output_dir,\n",
    "        save_steps=SAVE_STEPS,\n",
    "        logging_steps=LOGGING_STEPS,\n",
    "        skip_validation=SKIP_VALIDATION,\n",
    "        weight_and_biases=WEIGHTS_AND_BIASES_ENABLED,\n",
    "        use_FP16=USE_FP16,\n",
    "        notation=\"xLANplus\" if XLANPLUS_ENABLED else \"xLAN\",\n",
    "        peft=model,\n",
    "    )\n",
    "\n",
    "    # trainer.train() # TODO: uncomment later\n",
    "    print(\"trainer.train()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b580b06e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:42.782976Z",
     "iopub.status.busy": "2024-05-08T11:57:42.782878Z",
     "iopub.status.idle": "2024-05-08T11:57:42.784478Z",
     "shell.execute_reply": "2024-05-08T11:57:42.784254Z"
    },
    "papermill": {
     "duration": 0.003629,
     "end_time": "2024-05-08T11:57:42.785243",
     "exception": false,
     "start_time": "2024-05-08T11:57:42.781614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def push_model_to_hf(model, name):\n",
    "    # TODO: handle login...\n",
    "    # model.push_to_hub(\"your-name/bigscience/mt0-large-lora\")\n",
    "    print(f\"push_model_to_hf(model={model}, name={name})\")\n",
    "    # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbcb61f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T11:57:42.787738Z",
     "iopub.status.busy": "2024-05-08T11:57:42.787642Z",
     "iopub.status.idle": "2024-05-08T11:57:44.183214Z",
     "shell.execute_reply": "2024-05-08T11:57:44.182925Z"
    },
    "papermill": {
     "duration": 1.39784,
     "end_time": "2024-05-08T11:57:44.184160",
     "exception": false,
     "start_time": "2024-05-08T11:57:42.786320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(76, 768)\n",
      "        (wpe): Embedding(512, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=128, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=76, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "dataset: ./data/tokens/carlsen_max_768.tok\n",
      "output_dir: models/Leon-Chess-350k-BOS_LoRA_f'carlsen'\n",
      "trainer.train()\n",
      "push_model_to_hf(model=PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(76, 768)\n",
      "        (wpe): Embedding(512, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=128, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=76, bias=False)\n",
      "    )\n",
      "  )\n",
      "), name=Leon-Chess-350k-BOS_LoRA_f'carlsen')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larscarlschmid/Documents/_repos/ChessOps/venv/lib/python3.11/site-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "train_model(model, dataset, output_dir + model_name)\n",
    "push_model_to_hf(model, model_name)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "duration": 4.028728,
   "end_time": "2024-05-08T11:57:44.705589",
   "exception": null,
   "input_path": "/var/folders/h3/3d89qwl94937xcsw4qq0hh2c0000gn/T/tmpojhf8uit.ipynb",
   "output_path": "/Users/larscarlschmid/Documents/_repos/ChessOps/output/finetune.ipynb",
   "parameters": {
    "chess_player": "f'carlsen'",
    "product": {
     "nb": "/Users/larscarlschmid/Documents/_repos/ChessOps/output/finetune.ipynb"
    }
   },
   "start_time": "2024-05-08T11:57:40.676861"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}