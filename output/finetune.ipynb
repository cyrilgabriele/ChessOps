{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f22fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:33.654070Z",
     "iopub.status.busy": "2024-05-19T15:06:33.653457Z",
     "iopub.status.idle": "2024-05-19T15:06:33.659842Z",
     "shell.execute_reply": "2024-05-19T15:06:33.659294Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.010299,
     "end_time": "2024-05-19T15:06:33.660972",
     "exception": false,
     "start_time": "2024-05-19T15:06:33.650673",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# declare a list tasks whose products you want to use as inputs\n",
    "upstream = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8cd7881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:33.665399Z",
     "iopub.status.busy": "2024-05-19T15:06:33.665056Z",
     "iopub.status.idle": "2024-05-19T15:06:33.667905Z",
     "shell.execute_reply": "2024-05-19T15:06:33.667359Z"
    },
    "papermill": {
     "duration": 0.005951,
     "end_time": "2024-05-19T15:06:33.668939",
     "exception": false,
     "start_time": "2024-05-19T15:06:33.662988",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "chess_player = \"f'kasparov'\"\n",
    "dataset = \"./data/tokens/kasparov_max_768_bos.tok\"\n",
    "product = {\"nb\": \"/teamspace/studios/this_studio/ChessOps/output/finetune.ipynb\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba60421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:33.672931Z",
     "iopub.status.busy": "2024-05-19T15:06:33.672578Z",
     "iopub.status.idle": "2024-05-19T15:06:37.789264Z",
     "shell.execute_reply": "2024-05-19T15:06:37.788595Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 4.120133,
     "end_time": "2024-05-19T15:06:37.790604",
     "exception": false,
     "start_time": "2024-05-19T15:06:33.670471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from src.train import ChessTrainer\n",
    "from peft import LoraConfig, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd976baf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:37.795879Z",
     "iopub.status.busy": "2024-05-19T15:06:37.795246Z",
     "iopub.status.idle": "2024-05-19T15:06:37.798791Z",
     "shell.execute_reply": "2024-05-19T15:06:37.798248Z"
    },
    "papermill": {
     "duration": 0.006903,
     "end_time": "2024-05-19T15:06:37.799802",
     "exception": false,
     "start_time": "2024-05-19T15:06:37.792899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## HYPERPARAMETERS\n",
    "BATCH_SIZE = 16  # use the largest batch size that fits on your GPU\n",
    "SAVE_STEPS = 2000  # how often to save a checkpoint\n",
    "LOGGING_STEPS = 50  # how often to validate model and publish it to Weights & Biases\n",
    "EPOCHS = 10  # how many epochs to train for - how many times to go through the dataset\n",
    "LEARNING_RATE = 0.0001  # learning rate - how fast the model should learn\n",
    "SKIP_VALIDATION = True  # skip validation and only save model checkpoints\n",
    "WEIGHTS_AND_BIASES_ENABLED = True  # enable logging to Weights & Biases\n",
    "USE_FP16 = True  # enable mixed precision training (GPU only)\n",
    "XLANPLUS_ENABLED = True  # use xLanPlus tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d36cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:37.804115Z",
     "iopub.status.busy": "2024-05-19T15:06:37.803665Z",
     "iopub.status.idle": "2024-05-19T15:06:37.806354Z",
     "shell.execute_reply": "2024-05-19T15:06:37.805805Z"
    },
    "papermill": {
     "duration": 0.005918,
     "end_time": "2024-05-19T15:06:37.807427",
     "exception": false,
     "start_time": "2024-05-19T15:06:37.801509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MODEL\n",
    "PEFT_BASE_MODEL = \"Leon-LLM/Leon-Chess-350k-Plus\" # base model to be loaded (from hugging face) for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb72c757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:37.811746Z",
     "iopub.status.busy": "2024-05-19T15:06:37.811283Z",
     "iopub.status.idle": "2024-05-19T15:06:37.814173Z",
     "shell.execute_reply": "2024-05-19T15:06:37.813628Z"
    },
    "papermill": {
     "duration": 0.006088,
     "end_time": "2024-05-19T15:06:37.815172",
     "exception": false,
     "start_time": "2024-05-19T15:06:37.809084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CONFIG FOR FINE-TUNING\n",
    "R = 128  # lower means faster training, but might underfit because of less complexity (experiments don't show that training time increases, which is rather weird)\n",
    "LORA_ALPHA = 32  # scaling factor that adjusts the magnitude of the combined result (balances the pretrained model‚Äôs knowledge and the new task-specific adaptation)\n",
    "LORA_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d41fa159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:37.819443Z",
     "iopub.status.busy": "2024-05-19T15:06:37.818975Z",
     "iopub.status.idle": "2024-05-19T15:06:37.821923Z",
     "shell.execute_reply": "2024-05-19T15:06:37.821380Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 0.006092,
     "end_time": "2024-05-19T15:06:37.822902",
     "exception": false,
     "start_time": "2024-05-19T15:06:37.816810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PATHS\n",
    "# model_name = f\"{PEFT_BASE_MODEL.split('/')[1]}_LoRA_{chess_player}\".replace(\"'\", \"\")\n",
    "model_name = f\"{PEFT_BASE_MODEL.split('/')[1]}_LoRA_{chess_player}_{EPOCHS}E_{LEARNING_RATE}LR\".replace(\"'\", \"\")\n",
    "output_path = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac2b52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:37.827307Z",
     "iopub.status.busy": "2024-05-19T15:06:37.826847Z",
     "iopub.status.idle": "2024-05-19T15:06:37.830805Z",
     "shell.execute_reply": "2024-05-19T15:06:37.830264Z"
    },
    "papermill": {
     "duration": 0.007276,
     "end_time": "2024-05-19T15:06:37.831852",
     "exception": false,
     "start_time": "2024-05-19T15:06:37.824576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(debug=True):\n",
    "    peft_config = LoraConfig(  # https://huggingface.co/docs/peft/v0.10.0/en/package_reference/lora#peft.LoraConfig\n",
    "        task_type=\"CAUSAL_LM\", # This does not need to be changed for our use case\n",
    "        inference_mode=False, # don't change this for training, only later for inference\n",
    "        r=R,  # lower means faster training, but might underfit because of less complexity (experiments don't show that training time increases, which is rather weird)\n",
    "        lora_alpha=LORA_ALPHA,  # scaling factor that adjusts the magnitude of the combined result (balances the pretrained model‚Äôs knowledge and the new task-specific adaptation)\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "    )\n",
    "\n",
    "    peft_model = get_peft_model(\n",
    "        AutoModelForCausalLM.from_pretrained(PEFT_BASE_MODEL), peft_config\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        print(f\"peft_model created: {peft_model}\")\n",
    "\n",
    "    return peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae457cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:37.836179Z",
     "iopub.status.busy": "2024-05-19T15:06:37.835722Z",
     "iopub.status.idle": "2024-05-19T15:06:37.839498Z",
     "shell.execute_reply": "2024-05-19T15:06:37.838959Z"
    },
    "papermill": {
     "duration": 0.00694,
     "end_time": "2024-05-19T15:06:37.840488",
     "exception": false,
     "start_time": "2024-05-19T15:06:37.833548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataset, output_dir, debug=True):\n",
    "    if debug:\n",
    "        print(f\"model: {model}\")\n",
    "        print(f\"dataset: {dataset}\")\n",
    "        print(f\"output_dir: {output_dir}\")\n",
    "\n",
    "    trainer = ChessTrainer(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        epochs=EPOCHS,\n",
    "        input_file=dataset,\n",
    "        output_dir=output_dir,\n",
    "        save_steps=SAVE_STEPS,\n",
    "        logging_steps=LOGGING_STEPS,\n",
    "        skip_validation=SKIP_VALIDATION,\n",
    "        weight_and_biases=WEIGHTS_AND_BIASES_ENABLED,\n",
    "        use_FP16=USE_FP16,\n",
    "        notation=\"xLANplus\" if XLANPLUS_ENABLED else \"xLAN\",\n",
    "        peft=model,\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e50ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:37.844852Z",
     "iopub.status.busy": "2024-05-19T15:06:37.844509Z",
     "iopub.status.idle": "2024-05-19T15:06:37.847513Z",
     "shell.execute_reply": "2024-05-19T15:06:37.846941Z"
    },
    "papermill": {
     "duration": 0.006316,
     "end_time": "2024-05-19T15:06:37.848517",
     "exception": false,
     "start_time": "2024-05-19T15:06:37.842201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def push_model_to_hf(model, name, debug=True):\n",
    "    if debug:\n",
    "        print(f\"push_model_to_hf(model={model}, name={name})\")\n",
    "    model.push_to_hub(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0f868ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:06:37.852921Z",
     "iopub.status.busy": "2024-05-19T15:06:37.852592Z",
     "iopub.status.idle": "2024-05-19T15:19:30.715081Z",
     "shell.execute_reply": "2024-05-19T15:19:30.714372Z"
    },
    "papermill": {
     "duration": 772.86637,
     "end_time": "2024-05-19T15:19:30.716622",
     "exception": false,
     "start_time": "2024-05-19T15:06:37.850252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peft_model created: PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(82, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=128, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=82, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "model: PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(82, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=128, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=82, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "dataset: ./data/tokens/kasparov_max_768_bos.tok\n",
      "output_dir: models/Leon-Chess-350k-Plus_LoRA_fkasparov_10E_0.0001LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mschmila7\u001b[0m (\u001b[33mleon-llm\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/teamspace/studios/this_studio/ChessOps/wandb/run-20240519_150639-td54erq5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmodels\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps/runs/td54erq5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1330' max='1330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1330/1330 12:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.318400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.885400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.213600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.978200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.951600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.915800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.885400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.853700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.823200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.803200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.792700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.784600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.789400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.781300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.781300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.004 MB of 0.004 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.004 MB of 0.004 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.026 MB of 0.026 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/grad_norm ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/learning_rate ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 8766887507988480.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 1330\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 0.60837\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 0.7813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 1.16237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 761.8881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 27.852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 1.746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmodels\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps/runs/td54erq5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_150639-td54erq5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "push_model_to_hf(model=PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(82, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=128, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=82, bias=False)\n",
      "    )\n",
      "  )\n",
      "), name=Leon-Chess-350k-Plus_LoRA_fkasparov_10E_0.0001LR)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68a4fd9716c43599312010ca8e8855e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/18.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model()\n",
    "train_model(model, dataset, output_path + model_name)\n",
    "push_model_to_hf(model, model_name)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "duration": 779.349535,
   "end_time": "2024-05-19T15:19:32.344900",
   "exception": null,
   "input_path": "/tmp/tmpw13ray2g.ipynb",
   "output_path": "/teamspace/studios/this_studio/ChessOps/output/finetune.ipynb",
   "parameters": {
    "chess_player": "f'kasparov'",
    "dataset": "./data/tokens/kasparov_max_768_bos.tok",
    "product": {
     "nb": "/teamspace/studios/this_studio/ChessOps/output/finetune.ipynb"
    }
   },
   "start_time": "2024-05-19T15:06:32.995365"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04232ebeb93442d19600c36d35d652d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3c0c3b8e1d3145fbbed457628c43e7da",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_0ab99920fa9040189c7eb86bc5710906",
       "tabbable": null,
       "tooltip": null,
       "value": "adapter_model.safetensors:‚Äá100%"
      }
     },
     "0ab99920fa9040189c7eb86bc5710906": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3c0c3b8e1d3145fbbed457628c43e7da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "499c8022ef6844419529a54e550718bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_80c5c165baf84350bd444da6799fe02b",
       "max": 18877512.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d0802685ee374327bbd9dc2d784a74f0",
       "tabbable": null,
       "tooltip": null,
       "value": 18877512.0
      }
     },
     "4d301e19c89440f7820d418736ecbfbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_daa2c14ed491459b9e29e569d08b3ce3",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_8268255377714904ba2ad23e440be0fb",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá18.9M/18.9M‚Äá[00:00&lt;00:00,‚Äá72.3MB/s]"
      }
     },
     "80c5c165baf84350bd444da6799fe02b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8268255377714904ba2ad23e440be0fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aaddaf4d81434b54b8f2a242827cc846": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c68a4fd9716c43599312010ca8e8855e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_04232ebeb93442d19600c36d35d652d9",
        "IPY_MODEL_499c8022ef6844419529a54e550718bc",
        "IPY_MODEL_4d301e19c89440f7820d418736ecbfbf"
       ],
       "layout": "IPY_MODEL_aaddaf4d81434b54b8f2a242827cc846",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d0802685ee374327bbd9dc2d784a74f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "daa2c14ed491459b9e29e569d08b3ce3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}