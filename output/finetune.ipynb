{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a32a6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:18.096328Z",
     "iopub.status.busy": "2024-05-08T15:14:18.095829Z",
     "iopub.status.idle": "2024-05-08T15:14:18.102161Z",
     "shell.execute_reply": "2024-05-08T15:14:18.101612Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.010186,
     "end_time": "2024-05-08T15:14:18.103228",
     "exception": false,
     "start_time": "2024-05-08T15:14:18.093042",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# declare a list tasks whose products you want to use as inputs\n",
    "upstream = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07167733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:18.108161Z",
     "iopub.status.busy": "2024-05-08T15:14:18.107863Z",
     "iopub.status.idle": "2024-05-08T15:14:18.110658Z",
     "shell.execute_reply": "2024-05-08T15:14:18.110110Z"
    },
    "papermill": {
     "duration": 0.00595,
     "end_time": "2024-05-08T15:14:18.111667",
     "exception": false,
     "start_time": "2024-05-08T15:14:18.105717",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "chess_player = \"f'kasparov'\"\n",
    "dataset = \"./data/tokens/kasparov_max_768.tok\"\n",
    "product = {\"nb\": \"/teamspace/studios/this_studio/ChessOps/output/finetune.ipynb\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dceeb8ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:18.115445Z",
     "iopub.status.busy": "2024-05-08T15:14:18.115282Z",
     "iopub.status.idle": "2024-05-08T15:14:21.139862Z",
     "shell.execute_reply": "2024-05-08T15:14:21.139132Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 3.028194,
     "end_time": "2024-05-08T15:14:21.141382",
     "exception": false,
     "start_time": "2024-05-08T15:14:18.113188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from src.train import ChessTrainer\n",
    "from peft import LoraConfig, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4835db9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:21.146375Z",
     "iopub.status.busy": "2024-05-08T15:14:21.145686Z",
     "iopub.status.idle": "2024-05-08T15:14:21.149351Z",
     "shell.execute_reply": "2024-05-08T15:14:21.148744Z"
    },
    "papermill": {
     "duration": 0.0071,
     "end_time": "2024-05-08T15:14:21.150442",
     "exception": false,
     "start_time": "2024-05-08T15:14:21.143342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## HYPERPARAMETERS\n",
    "BATCH_SIZE = 4  # use the largest batch size that fits on your GPU\n",
    "SAVE_STEPS = 2000  # how often to save a checkpoint\n",
    "LOGGING_STEPS = 50  # how often to validate model and publish it to Weights & Biases\n",
    "EPOCHS = 1  # how many epochs to train for - how many times to go through the dataset\n",
    "LEARNING_RATE = 0.0001  # learning rate - how fast the model should learn\n",
    "SKIP_VALIDATION = True  # skip validation and only save model checkpoints\n",
    "WEIGHTS_AND_BIASES_ENABLED = True  # enable logging to Weights & Biases\n",
    "USE_FP16 = True  # enable mixed precision training (GPU only)\n",
    "XLANPLUS_ENABLED = True  # use xLanPlus tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7075fb70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:21.154837Z",
     "iopub.status.busy": "2024-05-08T15:14:21.154339Z",
     "iopub.status.idle": "2024-05-08T15:14:21.156992Z",
     "shell.execute_reply": "2024-05-08T15:14:21.156461Z"
    },
    "papermill": {
     "duration": 0.005865,
     "end_time": "2024-05-08T15:14:21.157994",
     "exception": false,
     "start_time": "2024-05-08T15:14:21.152129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MODEL\n",
    "PEFT_BASE_MODEL = \"Leon-LLM/Leon-Chess-350k-Plus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e732ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:21.162189Z",
     "iopub.status.busy": "2024-05-08T15:14:21.161725Z",
     "iopub.status.idle": "2024-05-08T15:14:21.164603Z",
     "shell.execute_reply": "2024-05-08T15:14:21.164084Z"
    },
    "papermill": {
     "duration": 0.005978,
     "end_time": "2024-05-08T15:14:21.165586",
     "exception": false,
     "start_time": "2024-05-08T15:14:21.159608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CONFIG FOR FINE-TUNING\n",
    "R = 128  # lower means faster training, but might underfit because of less complexity (experiments don't show that training time increases, which is rather weird)\n",
    "LORA_ALPHA = 32  # scaling factor that adjusts the magnitude of the combined result (balances the pretrained model‚Äôs knowledge and the new task-specific adaptation)\n",
    "LORA_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0b6dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:21.169635Z",
     "iopub.status.busy": "2024-05-08T15:14:21.169334Z",
     "iopub.status.idle": "2024-05-08T15:14:21.172277Z",
     "shell.execute_reply": "2024-05-08T15:14:21.171743Z"
    },
    "papermill": {
     "duration": 0.006057,
     "end_time": "2024-05-08T15:14:21.173260",
     "exception": false,
     "start_time": "2024-05-08T15:14:21.167203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PATHS\n",
    "# dataset = \"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/data/tokens/carlsen_max_768.tok\"\n",
    "# dataset = \"./data/tokens/carlsen_max_768.tok\"\n",
    "# output_dir = f\"/Users/cyrilgabriele/Documents/School/00_Courses/03_MLOPS/04_Project/ChessOps/models/\"\n",
    "output_dir = \"models/\"\n",
    "model_name = f\"{PEFT_BASE_MODEL.split('/')[1]}_LoRA_{chess_player}\".replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec2a252a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:21.178180Z",
     "iopub.status.busy": "2024-05-08T15:14:21.177709Z",
     "iopub.status.idle": "2024-05-08T15:14:21.181294Z",
     "shell.execute_reply": "2024-05-08T15:14:21.180774Z"
    },
    "papermill": {
     "duration": 0.007294,
     "end_time": "2024-05-08T15:14:21.182269",
     "exception": false,
     "start_time": "2024-05-08T15:14:21.174975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    peft_config = LoraConfig(  # https://huggingface.co/docs/peft/v0.10.0/en/package_reference/lora#peft.LoraConfig\n",
    "        task_type=\"CAUSAL_LM\",  # This does not need to be changed for our use case\n",
    "        inference_mode=False,  # don't change this for training, only later for inference\n",
    "        r=R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "    )\n",
    "\n",
    "    peft_model = get_peft_model(\n",
    "        AutoModelForCausalLM.from_pretrained(PEFT_BASE_MODEL), peft_config\n",
    "    )\n",
    "\n",
    "    return peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9293971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:21.187979Z",
     "iopub.status.busy": "2024-05-08T15:14:21.187670Z",
     "iopub.status.idle": "2024-05-08T15:14:21.192124Z",
     "shell.execute_reply": "2024-05-08T15:14:21.191167Z"
    },
    "papermill": {
     "duration": 0.008551,
     "end_time": "2024-05-08T15:14:21.193998",
     "exception": false,
     "start_time": "2024-05-08T15:14:21.185447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataset, output_dir, debug=True):\n",
    "    if debug:\n",
    "        print(f\"model: {model}\")\n",
    "        print(f\"dataset: {dataset}\")\n",
    "        print(f\"output_dir: {output_dir}\")\n",
    "\n",
    "    trainer = ChessTrainer(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        epochs=EPOCHS,\n",
    "        input_file=dataset,\n",
    "        output_dir=output_dir,\n",
    "        save_steps=SAVE_STEPS,\n",
    "        logging_steps=LOGGING_STEPS,\n",
    "        skip_validation=SKIP_VALIDATION,\n",
    "        weight_and_biases=WEIGHTS_AND_BIASES_ENABLED,\n",
    "        use_FP16=USE_FP16,\n",
    "        notation=\"xLANplus\" if XLANPLUS_ENABLED else \"xLAN\",\n",
    "        peft=model,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    #print(\"trainer.train()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c345e20b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:21.199111Z",
     "iopub.status.busy": "2024-05-08T15:14:21.198694Z",
     "iopub.status.idle": "2024-05-08T15:14:21.202678Z",
     "shell.execute_reply": "2024-05-08T15:14:21.201817Z"
    },
    "papermill": {
     "duration": 0.008137,
     "end_time": "2024-05-08T15:14:21.204255",
     "exception": false,
     "start_time": "2024-05-08T15:14:21.196118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def push_model_to_hf(model, name):\n",
    "    print(f\"push_model_to_hf(model={model}, name={name})\")\n",
    "    model.push_to_hub(model_name)\n",
    "    # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e363476a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T15:14:21.209688Z",
     "iopub.status.busy": "2024-05-08T15:14:21.209433Z",
     "iopub.status.idle": "2024-05-08T15:14:33.875334Z",
     "shell.execute_reply": "2024-05-08T15:14:33.874770Z"
    },
    "papermill": {
     "duration": 12.669821,
     "end_time": "2024-05-08T15:14:33.876739",
     "exception": false,
     "start_time": "2024-05-08T15:14:21.206918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(82, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=128, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=82, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "dataset: ./data/tokens/kasparov_max_768.tok\n",
      "output_dir: models/Leon-Chess-350k-Plus_LoRA_fkasparov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mschmila7\u001b[0m (\u001b[33mleon-llm\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/teamspace/studios/this_studio/ChessOps/wandb/run-20240508_151422-uwv1plnu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmodels\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps/runs/uwv1plnu\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.004 MB of 0.004 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.004 MB of 0.004 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.025 MB of 0.025 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/epoch ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/global_step ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 13008338380800.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 3.85543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 1.7654\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 19.826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 5.098\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmodels\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps/runs/uwv1plnu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240508_151422-uwv1plnu/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "push_model_to_hf(model=PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(82, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=128, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=82, bias=False)\n",
      "    )\n",
      "  )\n",
      "), name=Leon-Chess-350k-Plus_LoRA_fkasparov)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a16437a04ac41d6be753b0c8b479443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/18.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model()\n",
    "train_model(model, dataset, output_dir + model_name)\n",
    "push_model_to_hf(model, model_name)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "duration": 17.763865,
   "end_time": "2024-05-08T15:14:35.202644",
   "exception": null,
   "input_path": "/tmp/tmpare4gs88.ipynb",
   "output_path": "/teamspace/studios/this_studio/ChessOps/output/finetune.ipynb",
   "parameters": {
    "chess_player": "f'kasparov'",
    "dataset": "./data/tokens/kasparov_max_768.tok",
    "product": {
     "nb": "/teamspace/studios/this_studio/ChessOps/output/finetune.ipynb"
    }
   },
   "start_time": "2024-05-08T15:14:17.438779"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "13156d27835d4a0d8ca65173a555816b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1ae2d54880d0474f86ce6a8013cd283a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5cbceef001e9406d9309153878e29f93",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ce07442b78204d40a0d515ede8e0f960",
       "tabbable": null,
       "tooltip": null,
       "value": "adapter_model.safetensors:‚Äá100%"
      }
     },
     "2a16437a04ac41d6be753b0c8b479443": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ae2d54880d0474f86ce6a8013cd283a",
        "IPY_MODEL_6b8ebb468c134f7b801e50d29c8840ae",
        "IPY_MODEL_b9065092fc734af2b7ff48a955911c2b"
       ],
       "layout": "IPY_MODEL_849664d7b6ea4aab85857b4976f86462",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3bf5127894df4cf4b6f302c4091fbade": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a95344127414d9d80cb0138b2f2d6c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5cbceef001e9406d9309153878e29f93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b8ebb468c134f7b801e50d29c8840ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3bf5127894df4cf4b6f302c4091fbade",
       "max": 18877512.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4a95344127414d9d80cb0138b2f2d6c1",
       "tabbable": null,
       "tooltip": null,
       "value": 18877512.0
      }
     },
     "849664d7b6ea4aab85857b4976f86462": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b9065092fc734af2b7ff48a955911c2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c74f6bcf3ef845cb8bd2cb6fc39b0f50",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_13156d27835d4a0d8ca65173a555816b",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá18.9M/18.9M‚Äá[00:00&lt;00:00,‚Äá57.4MB/s]"
      }
     },
     "c74f6bcf3ef845cb8bd2cb6fc39b0f50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce07442b78204d40a0d515ede8e0f960": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}