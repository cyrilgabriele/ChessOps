{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548c241c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:52.887567Z",
     "iopub.status.busy": "2024-05-19T16:13:52.887203Z",
     "iopub.status.idle": "2024-05-19T16:13:52.893483Z",
     "shell.execute_reply": "2024-05-19T16:13:52.892928Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.009616,
     "end_time": "2024-05-19T16:13:52.894550",
     "exception": false,
     "start_time": "2024-05-19T16:13:52.884934",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# declare a list tasks whose products you want to use as inputs\n",
    "upstream = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b4256a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:52.898815Z",
     "iopub.status.busy": "2024-05-19T16:13:52.898502Z",
     "iopub.status.idle": "2024-05-19T16:13:52.901404Z",
     "shell.execute_reply": "2024-05-19T16:13:52.900856Z"
    },
    "papermill": {
     "duration": 0.006294,
     "end_time": "2024-05-19T16:13:52.902546",
     "exception": false,
     "start_time": "2024-05-19T16:13:52.896252",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "chess_player = \"f'carlsen'\"\n",
    "dataset = \"./data/tokens/carlsen_max_768_bos.tok\"\n",
    "product = {\"nb\": \"/teamspace/studios/this_studio/ChessOps/output/finetune.ipynb\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833704a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:52.907268Z",
     "iopub.status.busy": "2024-05-19T16:13:52.906968Z",
     "iopub.status.idle": "2024-05-19T16:13:55.978522Z",
     "shell.execute_reply": "2024-05-19T16:13:55.977862Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 3.075853,
     "end_time": "2024-05-19T16:13:55.979996",
     "exception": false,
     "start_time": "2024-05-19T16:13:52.904143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from src.train import ChessTrainer\n",
    "from peft import LoraConfig, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b6ebbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:55.984822Z",
     "iopub.status.busy": "2024-05-19T16:13:55.984307Z",
     "iopub.status.idle": "2024-05-19T16:13:55.988029Z",
     "shell.execute_reply": "2024-05-19T16:13:55.987461Z"
    },
    "papermill": {
     "duration": 0.007199,
     "end_time": "2024-05-19T16:13:55.989117",
     "exception": false,
     "start_time": "2024-05-19T16:13:55.981918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## HYPERPARAMETERS\n",
    "BATCH_SIZE = 16  # use the largest batch size that fits on your GPU\n",
    "SAVE_STEPS = 2000  # how often to save a checkpoint\n",
    "LOGGING_STEPS = 50  # how often to validate model and publish it to Weights & Biases\n",
    "EPOCHS = 10  # how many epochs to train for - how many times to go through the dataset\n",
    "LEARNING_RATE = 0.0001  # learning rate - how fast the model should learn\n",
    "SKIP_VALIDATION = True  # skip validation and only save model checkpoints\n",
    "WEIGHTS_AND_BIASES_ENABLED = True  # enable logging to Weights & Biases\n",
    "USE_FP16 = True  # enable mixed precision training (GPU only)\n",
    "XLANPLUS_ENABLED = True  # use xLanPlus tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1812fdf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:55.993292Z",
     "iopub.status.busy": "2024-05-19T16:13:55.992877Z",
     "iopub.status.idle": "2024-05-19T16:13:55.995753Z",
     "shell.execute_reply": "2024-05-19T16:13:55.995189Z"
    },
    "papermill": {
     "duration": 0.006,
     "end_time": "2024-05-19T16:13:55.996733",
     "exception": false,
     "start_time": "2024-05-19T16:13:55.990733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MODEL\n",
    "PEFT_BASE_MODEL = \"Leon-LLM/Leon-Chess-350k-Plus\"  # base model to be loaded (from hugging face) for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4244e3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:56.000876Z",
     "iopub.status.busy": "2024-05-19T16:13:56.000556Z",
     "iopub.status.idle": "2024-05-19T16:13:56.003498Z",
     "shell.execute_reply": "2024-05-19T16:13:56.002956Z"
    },
    "papermill": {
     "duration": 0.006141,
     "end_time": "2024-05-19T16:13:56.004540",
     "exception": false,
     "start_time": "2024-05-19T16:13:55.998399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CONFIG FOR FINE-TUNING\n",
    "R = 128  # lower means faster training, but might underfit because of less complexity (experiments don't show that training time increases, which is rather weird)\n",
    "LORA_ALPHA = 32  # scaling factor that adjusts the magnitude of the combined result (balances the pretrained model’s knowledge and the new task-specific adaptation)\n",
    "LORA_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a10295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:56.009110Z",
     "iopub.status.busy": "2024-05-19T16:13:56.008779Z",
     "iopub.status.idle": "2024-05-19T16:13:56.011853Z",
     "shell.execute_reply": "2024-05-19T16:13:56.011317Z"
    },
    "papermill": {
     "duration": 0.006632,
     "end_time": "2024-05-19T16:13:56.012828",
     "exception": false,
     "start_time": "2024-05-19T16:13:56.006196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PATHS\n",
    "# model_name = f\"{PEFT_BASE_MODEL.split('/')[1]}_LoRA_{chess_player}\".replace(\"'\", \"\")\n",
    "model_name = f\"{PEFT_BASE_MODEL.split('/')[1]}_LoRA_{chess_player}_{EPOCHS}E_{LEARNING_RATE}LR\".replace(\n",
    "    \"'\", \"\"\n",
    ")\n",
    "output_path = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5243c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:56.017038Z",
     "iopub.status.busy": "2024-05-19T16:13:56.016733Z",
     "iopub.status.idle": "2024-05-19T16:13:56.020578Z",
     "shell.execute_reply": "2024-05-19T16:13:56.020033Z"
    },
    "papermill": {
     "duration": 0.007062,
     "end_time": "2024-05-19T16:13:56.021567",
     "exception": false,
     "start_time": "2024-05-19T16:13:56.014505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(debug=True):\n",
    "    peft_config = LoraConfig(  # https://huggingface.co/docs/peft/v0.10.0/en/package_reference/lora#peft.LoraConfig\n",
    "        task_type=\"CAUSAL_LM\",  # This does not need to be changed for our use case\n",
    "        inference_mode=False,  # don't change this for training, only later for inference\n",
    "        r=R,  # lower means faster training, but might underfit because of less complexity (experiments don't show that training time increases, which is rather weird)\n",
    "        lora_alpha=LORA_ALPHA,  # scaling factor that adjusts the magnitude of the combined result (balances the pretrained model’s knowledge and the new task-specific adaptation)\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "    )\n",
    "\n",
    "    peft_model = get_peft_model(\n",
    "        AutoModelForCausalLM.from_pretrained(PEFT_BASE_MODEL), peft_config\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        print(f\"peft_model created: {peft_model}\")\n",
    "\n",
    "    return peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2272562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:56.025807Z",
     "iopub.status.busy": "2024-05-19T16:13:56.025488Z",
     "iopub.status.idle": "2024-05-19T16:13:56.029401Z",
     "shell.execute_reply": "2024-05-19T16:13:56.028817Z"
    },
    "papermill": {
     "duration": 0.007213,
     "end_time": "2024-05-19T16:13:56.030475",
     "exception": false,
     "start_time": "2024-05-19T16:13:56.023262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataset, output_dir, debug=True):\n",
    "    if debug:\n",
    "        print(f\"model: {model}\")\n",
    "        print(f\"dataset: {dataset}\")\n",
    "        print(f\"output_dir: {output_dir}\")\n",
    "\n",
    "    trainer = ChessTrainer(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        epochs=EPOCHS,\n",
    "        input_file=dataset,\n",
    "        output_dir=output_dir,\n",
    "        save_steps=SAVE_STEPS,\n",
    "        logging_steps=LOGGING_STEPS,\n",
    "        skip_validation=SKIP_VALIDATION,\n",
    "        weight_and_biases=WEIGHTS_AND_BIASES_ENABLED,\n",
    "        use_FP16=USE_FP16,\n",
    "        notation=\"xLANplus\" if XLANPLUS_ENABLED else \"xLAN\",\n",
    "        peft=model,\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dacbff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:56.034834Z",
     "iopub.status.busy": "2024-05-19T16:13:56.034515Z",
     "iopub.status.idle": "2024-05-19T16:13:56.037546Z",
     "shell.execute_reply": "2024-05-19T16:13:56.036982Z"
    },
    "papermill": {
     "duration": 0.006414,
     "end_time": "2024-05-19T16:13:56.038591",
     "exception": false,
     "start_time": "2024-05-19T16:13:56.032177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def push_model_to_hf(model, name, debug=True):\n",
    "    if debug:\n",
    "        print(f\"push_model_to_hf(model={model}, name={name})\")\n",
    "    model.push_to_hub(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd9b7bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T16:13:56.042949Z",
     "iopub.status.busy": "2024-05-19T16:13:56.042628Z",
     "iopub.status.idle": "2024-05-19T16:47:34.871752Z",
     "shell.execute_reply": "2024-05-19T16:47:34.871138Z"
    },
    "papermill": {
     "duration": 2018.832611,
     "end_time": "2024-05-19T16:47:34.872941",
     "exception": false,
     "start_time": "2024-05-19T16:13:56.040330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peft_model created: PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(82, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=128, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=82, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "model: PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(82, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=128, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=82, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "dataset: ./data/tokens/carlsen_max_768_bos.tok\n",
      "output_dir: models/Leon-Chess-350k-Plus_LoRA_fcarlsen_10E_0.0001LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mschmila7\u001b[0m (\u001b[33mleon-llm\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/teamspace/studios/this_studio/ChessOps/wandb/run-20240519_161357-6alogt8k\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmodels\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps/runs/6alogt8k\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3500' max='3500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3500/3500 33:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.138900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.799000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.641100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.471100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.204600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.117100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.978600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.909900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.821800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.792600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.769900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.758900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.731700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.723500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.720300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.712800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.708700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.701200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.687600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.686800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.683900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.683900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.671900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.673600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.668200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.672400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.668500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.663200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.660300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.664200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.663900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.659900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.654900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.653300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.654700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.650300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.649100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.653800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.651700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.647300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.648200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.644100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.647400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.643400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.644400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.644100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.642100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.642300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.641200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.640600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.642700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.642400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.640900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.004 MB of 0.004 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.004 MB of 0.004 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.026 MB of 0.026 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train/grad_norm ▄▁▃▃▃▄▃▅▅▄▃▃▃▄▅▆▅▅█▃▃▃▅▃▆▃▄▄▃▂▅▄▃▃▃▂▄▃▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss █▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 2.312359537333248e+16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 3500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 0.23497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 0.6409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 0.81137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 2008.1916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 27.871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 1.743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmodels\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps/runs/6alogt8k\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/leon-llm/ChessOps\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240519_161357-6alogt8k/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "push_model_to_hf(model=PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2LMHeadModel(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(82, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=128, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=768, out_features=82, bias=False)\n",
      "    )\n",
      "  )\n",
      "), name=Leon-Chess-350k-Plus_LoRA_fcarlsen_10E_0.0001LR)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9ae863111f4946b548a4968d71c9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/18.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model()\n",
    "train_model(model, dataset, output_path + model_name)\n",
    "push_model_to_hf(model, model_name)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "duration": 2024.484567,
   "end_time": "2024-05-19T16:47:36.701644",
   "exception": null,
   "input_path": "/tmp/tmpm3ebl9hb.ipynb",
   "output_path": "/teamspace/studios/this_studio/ChessOps/output/finetune.ipynb",
   "parameters": {
    "chess_player": "f'carlsen'",
    "dataset": "./data/tokens/carlsen_max_768_bos.tok",
    "product": {
     "nb": "/teamspace/studios/this_studio/ChessOps/output/finetune.ipynb"
    }
   },
   "start_time": "2024-05-19T16:13:52.217077"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08822d3cabe14fe0bb46ca846a2232db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b169a9c06df4105b130debf6e81d988": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4ffc29cb94604e9592ed5bfa0d241b5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_adb2ef79883348928c503be51877da22",
       "placeholder": "​",
       "style": "IPY_MODEL_2b169a9c06df4105b130debf6e81d988",
       "tabbable": null,
       "tooltip": null,
       "value": "adapter_model.safetensors: 100%"
      }
     },
     "6b5a715ab04e40c4b34ba56555c83a79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f64f956f11c84548a7afff18542f3d49",
       "max": 18877512.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d999d0d07c034b35817e39aff6acc1aa",
       "tabbable": null,
       "tooltip": null,
       "value": 18877512.0
      }
     },
     "ad9ae863111f4946b548a4968d71c9da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4ffc29cb94604e9592ed5bfa0d241b5e",
        "IPY_MODEL_6b5a715ab04e40c4b34ba56555c83a79",
        "IPY_MODEL_f87d896fd11f4a389931194564161955"
       ],
       "layout": "IPY_MODEL_08822d3cabe14fe0bb46ca846a2232db",
       "tabbable": null,
       "tooltip": null
      }
     },
     "adb2ef79883348928c503be51877da22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d999d0d07c034b35817e39aff6acc1aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "db921d1167a04128b5faf5d03790aa72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e2b662cc290b441f96454069f3d4bd13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f64f956f11c84548a7afff18542f3d49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f87d896fd11f4a389931194564161955": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e2b662cc290b441f96454069f3d4bd13",
       "placeholder": "​",
       "style": "IPY_MODEL_db921d1167a04128b5faf5d03790aa72",
       "tabbable": null,
       "tooltip": null,
       "value": " 18.9M/18.9M [00:00&lt;00:00, 83.4MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}